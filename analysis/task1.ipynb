{
 "cells": [
  {
   "cell_type": "code",
   "id": "7c8f7acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:15:58.421785Z",
     "start_time": "2025-09-21T21:15:48.251100Z"
    }
   },
   "source": [
    "from typing import Dict, Tuple\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_path_in_parent(*args):\n",
    "    return os.path.abspath(os.path.join(os.getcwd(), '..', *args))\n",
    "\n",
    "def get_path_in_storage(*args):\n",
    "    return get_path_in_parent(\"storage\", *args)\n",
    "\n",
    "def get_model_paths(model_num: int):\n",
    "    path = get_path_in_parent(f\"yolo_model_{model_num}\")\n",
    "    return (\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.weights\"),\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.cfg\")\n",
    "    )\n",
    "\n",
    "def get_outputs(model_num: int) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    net = cv2.dnn.readNet(*get_model_paths(model_num))\n",
    "\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    outputs = {}\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(logistics_path, filename)))\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image,\n",
    "                                     scalefactor = 1 / 255.,\n",
    "                                     size=(416, 416),\n",
    "                                     mean=(0, 0, 0),\n",
    "                                     swapRB=True,\n",
    "                                     crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outputs[filename[:-4]] = net.forward(output_layers)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def save_outputs(model_num: int, outputs: Dict[str, Tuple[np.ndarray, ...]]) -> None:\n",
    "    \"\"\"Save a dict of tuples of arrays to an HDF5 file.\"\"\"\n",
    "    path = get_path_in_storage(f\"outputs_{model_num}.h5\")\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        for key, tup in outputs.items():\n",
    "            grp = f.create_group(str(key))\n",
    "            for i, arr in enumerate(tup):\n",
    "                grp.create_dataset(\n",
    "                    f\"array_{i}\", data=arr, compression=\"gzip\", compression_opts=1\n",
    "                )\n",
    "\n",
    "def load_outputs(model_num: int) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    \"\"\"Load a dict of tuples of arrays from an HDF5 file.\"\"\"\n",
    "    path = get_path_in_storage(f\"outputs_{model_num}.h5\")\n",
    "    outputs_loaded = {}\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            grp = f[key]\n",
    "            arrays = tuple(np.array(grp[subkey]) for subkey in sorted(grp.keys()))\n",
    "            outputs_loaded[key] = arrays\n",
    "    return outputs_loaded\n",
    "\n",
    "def apply_nms(outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "              conf_threshold: float = 0.5,\n",
    "              nms_threshold: float = 0.4\n",
    "             ) -> Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Apply Non-Max Suppression (NMS) to YOLO-style outputs.\n",
    "\n",
    "    Args:\n",
    "        outputs (dict): filename -> raw outputs from get_outputs()\n",
    "        conf_threshold (float): confidence threshold\n",
    "        nms_threshold (float): IoU threshold for NMS\n",
    "\n",
    "    Returns:\n",
    "        dict: filename -> (boxes, confidences, class_ids)\n",
    "    \"\"\"\n",
    "    filtered_outputs = {}\n",
    "\n",
    "    for fname, layer_outputs in outputs.items():\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "        # layer_outputs is a tuple of arrays (from YOLO forward pass)\n",
    "        for out in layer_outputs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = detection[4] * scores[class_id]\n",
    "\n",
    "                if confidence > conf_threshold:\n",
    "                    # YOLO gives relative coords\n",
    "                    # We donâ€™t know original image size here,\n",
    "                    # so assume normalization done elsewhere\n",
    "                    cx, cy, w, h = detection[0:4]\n",
    "                    x = cx - w / 2\n",
    "                    y = cy - h / 2\n",
    "                    boxes.append([int(x), int(y), int(w), int(h)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply NMS\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        final_boxes, final_confs, final_classes = [], [], []\n",
    "        if len(indices) > 0:\n",
    "            for i in indices.flatten():\n",
    "                final_boxes.append(boxes[i])\n",
    "                final_confs.append(confidences[i])\n",
    "                final_classes.append(class_ids[i])\n",
    "\n",
    "        filtered_outputs[fname] = (\n",
    "            np.array(final_boxes),\n",
    "            np.array(final_confs),\n",
    "            np.array(final_classes)\n",
    "        )\n",
    "\n",
    "    return filtered_outputs"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First time running model",
   "id": "8e54855bb6c05eff"
  },
  {
   "cell_type": "code",
   "id": "91bfaa836499a083",
   "metadata": {},
   "source": "outputs_1 = get_outputs(1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:13:34.337335Z",
     "start_time": "2025-09-18T03:13:23.848159Z"
    }
   },
   "cell_type": "code",
   "source": "save_outputs(1, outputs_1)",
   "id": "2536310679ddc363",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:15:43.827397Z",
     "start_time": "2025-09-18T03:13:34.340057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs_2 = get_outputs(2)\n",
    "save_outputs(2, outputs_2)"
   ],
   "id": "5a2e16de9562d875",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# After first time",
   "id": "8051748b089f85b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:16:06.031556Z",
     "start_time": "2025-09-21T21:15:58.430258Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_1 = load_outputs(1)",
   "id": "83cfa9e015e96754",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:16:13.455137Z",
     "start_time": "2025-09-21T21:16:06.171733Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_2 = load_outputs(2)",
   "id": "e06eaabec90b2acd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate Metrics",
   "id": "739e9c44b9fc1cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:21.914598Z",
     "start_time": "2025-09-21T21:22:21.911354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ground_truths() -> Dict[str, np.ndarray]:\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    res = {}\n",
    "\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(logistics_path, filename)\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                lines = []\n",
    "\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:  # expecting 5 values\n",
    "                        t = (\n",
    "                            int(parts[0]),\n",
    "                            float(parts[1]),\n",
    "                            float(parts[2]),\n",
    "                            float(parts[3]),\n",
    "                            float(parts[4]),\n",
    "                        )\n",
    "                        lines.append(t)\n",
    "\n",
    "                res[filename[:-4]] = np.array(lines)\n",
    "\n",
    "    return res"
   ],
   "id": "162773c6fde36e0a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:34.675662Z",
     "start_time": "2025-09-21T21:22:24.227377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.ops import box_iou\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "def cxcywh_to_xyxy(boxes: Tensor) -> Tensor:\n",
    "    # boxes: (N, 4) in [cx, cy, w, h]\n",
    "    xyxy = torch.zeros_like(boxes)\n",
    "    xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1\n",
    "    xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1\n",
    "    xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2\n",
    "    xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2\n",
    "    return xyxy\n",
    "\n",
    "def get_precision_and_recall(outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "                             ground_truths: Dict[str, np.ndarray],\n",
    "                             confidence_threshold: float,\n",
    "                             iou_threshold: float) -> Tuple[float, float]:\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    total_ground_truths = sum(len(gt) for _, gt in ground_truths.items())\n",
    "\n",
    "    for key in outputs:\n",
    "        output = outputs[key]\n",
    "        gt = ground_truths[key]\n",
    "\n",
    "        for feature_maps in output:\n",
    "            for detection in feature_maps:\n",
    "                box = detection[:4]\n",
    "                score = detection[4]\n",
    "                class_scores = detection[5:]\n",
    "                class_id = np.argmax(class_scores)\n",
    "\n",
    "                confidence = score * class_scores[class_id]\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                total_predictions += 1\n",
    "\n",
    "                # Extract IDs (shape: N,)\n",
    "                gt_ids = gt[:, 0]\n",
    "\n",
    "                # Extract boxes (shape: N, 4)\n",
    "                gt_boxes = gt[:, 1:5]\n",
    "\n",
    "                boxes_xyxy = cxcywh_to_xyxy(torch.tensor([box]))\n",
    "                gts_xyxy = cxcywh_to_xyxy(torch.tensor(gt_boxes))\n",
    "\n",
    "                ious = box_iou(boxes_xyxy, gts_xyxy)[0]\n",
    "                for iou, gt_id in zip(ious, gt_ids):\n",
    "                    if iou >= iou_threshold and class_id == gt_id:\n",
    "                        # This is a correct prediction\n",
    "                        correct_predictions += 1\n",
    "                        continue\n",
    "\n",
    "    print(correct_predictions, total_predictions, total_ground_truths)\n",
    "    return correct_predictions / total_predictions, correct_predictions / total_ground_truths"
   ],
   "id": "67aa1d95546b0b9c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:42.394930Z",
     "start_time": "2025-09-21T21:22:34.680811Z"
    }
   },
   "cell_type": "code",
   "source": "gts = get_ground_truths()",
   "id": "c51a17840ec56840",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:23:05.345753Z",
     "start_time": "2025-09-21T21:22:42.402246Z"
    }
   },
   "cell_type": "code",
   "source": "get_precision_and_recall(outputs_1, gts, 0.5, 0.4)",
   "id": "bb7dd455a2112a67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/4sm5vl2d7_xdd0jwk0tgnhn00000gn/T/ipykernel_5596/790632341.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  boxes_xyxy = cxcywh_to_xyxy(torch.tensor([box]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11109 12059 36721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9212206650634381, 0.3025244410555268)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:23:27.322288Z",
     "start_time": "2025-09-21T21:23:05.357337Z"
    }
   },
   "cell_type": "code",
   "source": "get_precision_and_recall(outputs_2, gts, 0.5, 0.4)",
   "id": "56a30942b7e88bab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15183 16082 36721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9440989926626041, 0.4134691321042455)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-21T21:23:27.329307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sweep over confidence thresholds\n",
    "thresholds = np.linspace(0, 1, 50)\n",
    "iou_threshold = 0.4\n",
    "\n",
    "precisions_1, recalls_1 = [], []\n",
    "precisions_2, recalls_2 = [], []\n",
    "\n",
    "for t in thresholds:\n",
    "    p1, r1 = get_precision_and_recall(outputs_1, gts, t, iou_threshold)\n",
    "    p2, r2 = get_precision_and_recall(outputs_2, gts, t, iou_threshold)\n",
    "\n",
    "    precisions_1.append(p1)\n",
    "    recalls_1.append(r1)\n",
    "    precisions_2.append(p2)\n",
    "    recalls_2.append(r2)\n",
    "\n",
    "# Plot PR curves\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recalls_1, precisions_1, label=\"Model 1\", marker=\"o\", markersize=3, linestyle=\"-\")\n",
    "plt.plot(recalls_2, precisions_2, label=\"Model 2\", marker=\"s\", markersize=3, linestyle=\"-\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "c9d2dd0e70bbb242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debugging / Testing",
   "id": "97a00d87efa917b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:12:19.439905Z",
     "start_time": "2025-09-18T02:12:19.376820Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Your class names\n",
    "classes = [\n",
    "    \"barcode\",\n",
    "    \"car\",\n",
    "    \"cardboard box\",\n",
    "    \"fire\",\n",
    "    \"forklift\",\n",
    "    \"freight container\",\n",
    "    \"gloves\",\n",
    "    \"helmet\",\n",
    "    \"ladder\",\n",
    "    \"license plate\",\n",
    "    \"person\",\n",
    "    \"qr code\",\n",
    "    \"road sign\",\n",
    "    \"safety vest\",\n",
    "    \"smoke\",\n",
    "    \"traffic cone\",\n",
    "    \"traffic light\",\n",
    "    \"truck\",\n",
    "    \"van\",\n",
    "    \"wood pallet\"\n",
    "]\n",
    "\n",
    "def run_single_prediction(model_num: int, image_path: str, output_path: str,\n",
    "                          conf_threshold: float = 0.5, nms_threshold: float = 0.4):\n",
    "\n",
    "    # Load YOLO model\n",
    "    net = cv2.dnn.readNet(*get_model_paths(model_num))\n",
    "\n",
    "    # Get output layers\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Load image\n",
    "    image = np.array(Image.open(image_path))\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Preprocess image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run inference\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "    # Process YOLO detections\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # Draw boxes\n",
    "    for i in indices:\n",
    "        i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = classes[class_ids[i]]\n",
    "        conf = confidences[i]\n",
    "\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, f\"{label} {conf:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Save output\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "# Usage:\n",
    "image_file = \"0bf5b2b81734d346d8c5034b92b5077e1625209617_jpeg_jpg.rf.04c6b8f7f044626b3f90e76296acb6b4.jpg\"\n",
    "run_single_prediction(1, image_file, \"test_pred.jpg\")\n"
   ],
   "id": "e99c37ed658305d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:16:50.469301Z",
     "start_time": "2025-09-18T02:16:04.415308Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def draw_predictions(outputs: List[Tuple[np.ndarray, ...]],\n",
    "                     model_num: int,\n",
    "                     class_names: List[str],\n",
    "                     conf_threshold: float = 0.5,\n",
    "                     nms_threshold: float = 0.4):\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    prediction_path = get_path_in_storage(\"prediction\")\n",
    "    os.makedirs(prediction_path, exist_ok=True)\n",
    "\n",
    "    # Load image filenames in the same order as get_outputs()\n",
    "    image_files = [f for f in os.listdir(logistics_path) if f.lower().endswith(\".jpg\")]\n",
    "\n",
    "    for img_idx, filename in enumerate(image_files):\n",
    "        image_path = os.path.join(logistics_path, filename)\n",
    "        image = np.array(Image.open(image_path))\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # YOLO raw outputs for this image\n",
    "        layer_outputs = outputs[img_idx]\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Loop through each output layer\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]  # class scores\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > conf_threshold:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply NMS to filter overlapping boxes\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        # Draw final boxes\n",
    "        for i in indices:\n",
    "            i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(class_names[class_ids[i]])\n",
    "            conf = confidences[i]\n",
    "\n",
    "            color = (0, 255, 0)  # Green boxes\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, f\"{label} {conf:.2f}\",\n",
    "                        (x, y - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Save prediction image\n",
    "        out_path = os.path.join(prediction_path, filename)\n",
    "        cv2.imwrite(out_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "draw_predictions(outputs_1, 1, [\n",
    "    \"barcode\",\n",
    "    \"car\",\n",
    "    \"cardboard box\",\n",
    "    \"fire\",\n",
    "    \"forklift\",\n",
    "    \"freight container\",\n",
    "    \"gloves\",\n",
    "    \"helmet\",\n",
    "    \"ladder\",\n",
    "    \"license plate\",\n",
    "    \"person\",\n",
    "    \"qr code\",\n",
    "    \"road sign\",\n",
    "    \"safety vest\",\n",
    "    \"smoke\",\n",
    "    \"traffic cone\",\n",
    "    \"traffic light\",\n",
    "    \"truck\",\n",
    "    \"van\",\n",
    "    \"wood pallet\"\n",
    "])"
   ],
   "id": "da5b8d62759c2b7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:00:58.204983Z",
     "start_time": "2025-09-18T03:00:58.185158Z"
    }
   },
   "cell_type": "code",
   "source": "os.listdir(get_path_in_storage(\"logistics\")) == os.listdir(get_path_in_storage(\"logistics\"))",
   "id": "414436830196a799",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c98aef8abf479df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
