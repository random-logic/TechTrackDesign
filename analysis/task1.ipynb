{
 "cells": [
  {
   "cell_type": "code",
   "id": "7c8f7acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:08:43.686659Z",
     "start_time": "2025-09-18T03:08:42.723050Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_path_in_parent(*args):\n",
    "    return os.path.abspath(os.path.join(os.getcwd(), '..', *args))\n",
    "\n",
    "def get_path_in_storage(*args):\n",
    "    return get_path_in_parent(\"storage\", *args)\n",
    "\n",
    "def get_model_paths(model_num: int):\n",
    "    path = get_path_in_parent(f\"yolo_model_{model_num}\")\n",
    "    return (\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.weights\"),\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.cfg\")\n",
    "    )\n",
    "\n",
    "def get_outputs(model_num: int) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    net = cv2.dnn.readNet(*get_model_paths(model_num))\n",
    "\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    outputs = {}\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(logistics_path, filename)))\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image,\n",
    "                                     scalefactor = 1 / 255.,\n",
    "                                     size=(416, 416),\n",
    "                                     mean=(0, 0, 0),\n",
    "                                     swapRB=True,\n",
    "                                     crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outputs[filename[:-4]] = net.forward(output_layers)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def save_outputs(model_num: int, outputs: List[Tuple[np.ndarray, ...]]) -> None:\n",
    "    with h5py.File(get_path_in_storage(f\"outputs_{model_num}.h5\"), \"w\") as f:\n",
    "        for i, tup in enumerate(outputs):\n",
    "            grp = f.create_group(f\"item_{i}\")\n",
    "            for j, arr in enumerate(tup):\n",
    "                grp.create_dataset(\n",
    "                    f\"array_{j}\", data=arr, compression=\"gzip\", compression_opts=1\n",
    "                )\n",
    "\n",
    "def load_outputs(model_num: int) -> List[Tuple[np.ndarray, ...]]:\n",
    "    with h5py.File(get_path_in_storage(f\"outputs_{model_num}.h5\"), \"r\") as f:\n",
    "        outputs_loaded = []\n",
    "        for key in f.keys():  # item_0, item_1, ...\n",
    "            grp = f[key]\n",
    "            arrays = tuple(np.array(grp[subkey]) for subkey in grp.keys())\n",
    "            outputs_loaded.append(arrays)\n",
    "\n",
    "    return outputs_loaded"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:08:43.703918Z",
     "start_time": "2025-09-18T03:08:43.693Z"
    }
   },
   "cell_type": "code",
   "source": "data_fileNames = { *os.listdir(get_path_in_storage(\"logistics\")) }",
   "id": "5b104ed66a2ccae1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First time running model",
   "id": "8e54855bb6c05eff"
  },
  {
   "cell_type": "code",
   "id": "91bfaa836499a083",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-18T03:08:44.144430Z"
    }
   },
   "source": [
    "outputs_1 = get_outputs(1)\n",
    "save_outputs(1, outputs_1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:08:38.211055Z",
     "start_time": "2025-09-18T02:40:43.229423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs_2 = get_outputs(2)\n",
    "save_outputs(2, outputs_2)"
   ],
   "id": "5a2e16de9562d875",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# After first time",
   "id": "8051748b089f85b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:08:38.215834Z",
     "start_time": "2025-09-18T02:55:34.092228Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_1 = load_outputs(1)",
   "id": "83cfa9e015e96754",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:08:38.216417Z",
     "start_time": "2025-09-18T02:55:39.954613Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_2 = load_outputs(2)",
   "id": "e06eaabec90b2acd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate Metrics",
   "id": "739e9c44b9fc1cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:57:56.611741Z",
     "start_time": "2025-09-18T02:57:56.608173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ground_truths() -> Dict[np.ndarray]:\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    res = {}\n",
    "\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(logistics_path, filename)\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                lines = []\n",
    "\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:  # expecting 5 values\n",
    "                        t = (\n",
    "                            int(parts[0]),\n",
    "                            float(parts[1]),\n",
    "                            float(parts[2]),\n",
    "                            float(parts[3]),\n",
    "                            float(parts[4]),\n",
    "                        )\n",
    "                        lines.append(t)\n",
    "\n",
    "                res[filename[:-4]] (np.array(lines))\n",
    "\n",
    "    return res"
   ],
   "id": "162773c6fde36e0a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:57:57.539178Z",
     "start_time": "2025-09-18T02:57:57.535366Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": [
    "from torchvision.ops import box_iou\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "def cxcywh_to_xyxy(boxes: Tensor) -> Tensor:\n",
    "    # boxes: (N, 4) in [cx, cy, w, h]\n",
    "    xyxy = torch.zeros_like(boxes)\n",
    "    xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1\n",
    "    xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1\n",
    "    xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2\n",
    "    xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2\n",
    "    return xyxy\n",
    "\n",
    "def get_precision_and_recall(outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "                             ground_truths: Dict[str, np.ndarray],\n",
    "                             confidence_threshold: float,\n",
    "                             iou_threshold: float) -> Tuple[float, float]:\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    total_ground_truths = sum(len(gt) for gt in ground_truths)\n",
    "\n",
    "    for key in outputs:\n",
    "        output = outputs[key]\n",
    "        gt = ground_truths[key]\n",
    "\n",
    "        for feature_maps in output:\n",
    "            for detection in feature_maps:\n",
    "                box = detection[:4]\n",
    "                score = detection[4]\n",
    "                class_scores = detection[5:]\n",
    "                class_id = np.argmax(class_scores)\n",
    "\n",
    "                confidence = score * class_scores[class_id]\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                total_predictions += 1\n",
    "\n",
    "                # Extract IDs (shape: N,)\n",
    "                gt_ids = gt[:, 0]\n",
    "\n",
    "                # Extract boxes (shape: N, 4)\n",
    "                gt_boxes = gt[:, 1:5]\n",
    "\n",
    "                boxes_xyxy = cxcywh_to_xyxy(torch.tensor([box]))\n",
    "                gts_xyxy = cxcywh_to_xyxy(torch.tensor(gt_boxes))\n",
    "\n",
    "                ious = box_iou(boxes_xyxy, gts_xyxy)[0]\n",
    "                for iou, gt_id in zip(ious, gt_ids):\n",
    "                    if iou >= iou_threshold and class_id == gt_id:\n",
    "                        # This is a correct prediction\n",
    "                        correct_predictions += 1\n",
    "                        continue\n",
    "\n",
    "    print(correct_predictions, total_predictions, total_ground_truths)\n",
    "    return correct_predictions / total_predictions, correct_predictions / total_ground_truths"
   ],
   "id": "67aa1d95546b0b9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:57:59.063193Z",
     "start_time": "2025-09-18T02:57:58.527181Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": "gts = get_ground_truths()",
   "id": "c51a17840ec56840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:58:20.672011Z",
     "start_time": "2025-09-18T02:57:59.455073Z"
    }
   },
   "cell_type": "code",
   "source": "get_precision_and_recall(outputs_1, gts, 0.5, 0.4)",
   "id": "bb7dd455a2112a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326 12059 36721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02703375072559914, 0.00887775387380518)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56a30942b7e88bab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debugging / Testing",
   "id": "97a00d87efa917b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:12:19.439905Z",
     "start_time": "2025-09-18T02:12:19.376820Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Your class names\n",
    "classes = [\n",
    "    \"barcode\",\n",
    "    \"car\",\n",
    "    \"cardboard box\",\n",
    "    \"fire\",\n",
    "    \"forklift\",\n",
    "    \"freight container\",\n",
    "    \"gloves\",\n",
    "    \"helmet\",\n",
    "    \"ladder\",\n",
    "    \"license plate\",\n",
    "    \"person\",\n",
    "    \"qr code\",\n",
    "    \"road sign\",\n",
    "    \"safety vest\",\n",
    "    \"smoke\",\n",
    "    \"traffic cone\",\n",
    "    \"traffic light\",\n",
    "    \"truck\",\n",
    "    \"van\",\n",
    "    \"wood pallet\"\n",
    "]\n",
    "\n",
    "def run_single_prediction(model_num: int, image_path: str, output_path: str,\n",
    "                          conf_threshold: float = 0.5, nms_threshold: float = 0.4):\n",
    "\n",
    "    # Load YOLO model\n",
    "    net = cv2.dnn.readNet(*get_model_paths(model_num))\n",
    "\n",
    "    # Get output layers\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Load image\n",
    "    image = np.array(Image.open(image_path))\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Preprocess image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run inference\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "    # Process YOLO detections\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > conf_threshold:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply NMS\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # Draw boxes\n",
    "    for i in indices:\n",
    "        i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = classes[class_ids[i]]\n",
    "        conf = confidences[i]\n",
    "\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, f\"{label} {conf:.2f}\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Save output\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "# Usage:\n",
    "image_file = \"0bf5b2b81734d346d8c5034b92b5077e1625209617_jpeg_jpg.rf.04c6b8f7f044626b3f90e76296acb6b4.jpg\"\n",
    "run_single_prediction(1, image_file, \"test_pred.jpg\")\n"
   ],
   "id": "e99c37ed658305d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T02:16:50.469301Z",
     "start_time": "2025-09-18T02:16:04.415308Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def draw_predictions(outputs: List[Tuple[np.ndarray, ...]],\n",
    "                     model_num: int,\n",
    "                     class_names: List[str],\n",
    "                     conf_threshold: float = 0.5,\n",
    "                     nms_threshold: float = 0.4):\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    prediction_path = get_path_in_storage(\"prediction\")\n",
    "    os.makedirs(prediction_path, exist_ok=True)\n",
    "\n",
    "    # Load image filenames in the same order as get_outputs()\n",
    "    image_files = [f for f in os.listdir(logistics_path) if f.lower().endswith(\".jpg\")]\n",
    "\n",
    "    for img_idx, filename in enumerate(image_files):\n",
    "        image_path = os.path.join(logistics_path, filename)\n",
    "        image = np.array(Image.open(image_path))\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # YOLO raw outputs for this image\n",
    "        layer_outputs = outputs[img_idx]\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        # Loop through each output layer\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]  # class scores\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > conf_threshold:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply NMS to filter overlapping boxes\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        # Draw final boxes\n",
    "        for i in indices:\n",
    "            i = i[0] if isinstance(i, (list, np.ndarray)) else i\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(class_names[class_ids[i]])\n",
    "            conf = confidences[i]\n",
    "\n",
    "            color = (0, 255, 0)  # Green boxes\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, f\"{label} {conf:.2f}\",\n",
    "                        (x, y - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Save prediction image\n",
    "        out_path = os.path.join(prediction_path, filename)\n",
    "        cv2.imwrite(out_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "draw_predictions(outputs_1, 1, [\n",
    "    \"barcode\",\n",
    "    \"car\",\n",
    "    \"cardboard box\",\n",
    "    \"fire\",\n",
    "    \"forklift\",\n",
    "    \"freight container\",\n",
    "    \"gloves\",\n",
    "    \"helmet\",\n",
    "    \"ladder\",\n",
    "    \"license plate\",\n",
    "    \"person\",\n",
    "    \"qr code\",\n",
    "    \"road sign\",\n",
    "    \"safety vest\",\n",
    "    \"smoke\",\n",
    "    \"traffic cone\",\n",
    "    \"traffic light\",\n",
    "    \"truck\",\n",
    "    \"van\",\n",
    "    \"wood pallet\"\n",
    "])"
   ],
   "id": "da5b8d62759c2b7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:00:58.204983Z",
     "start_time": "2025-09-18T03:00:58.185158Z"
    }
   },
   "cell_type": "code",
   "source": "os.listdir(get_path_in_storage(\"logistics\")) == os.listdir(get_path_in_storage(\"logistics\"))",
   "id": "414436830196a799",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8c98aef8abf479df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
