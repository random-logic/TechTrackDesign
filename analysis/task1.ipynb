{
 "cells": [
  {
   "cell_type": "code",
   "id": "7c8f7acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:15:58.421785Z",
     "start_time": "2025-09-21T21:15:48.251100Z"
    }
   },
   "source": [
    "from typing import Dict, Tuple\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_path_in_parent(*args):\n",
    "    return os.path.abspath(os.path.join(os.getcwd(), '..', *args))\n",
    "\n",
    "def get_path_in_storage(*args):\n",
    "    return get_path_in_parent(\"storage\", *args)\n",
    "\n",
    "def get_model_paths(model_num: int):\n",
    "    path = get_path_in_parent(f\"yolo_model_{model_num}\")\n",
    "    return (\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.weights\"),\n",
    "        os.path.join(path, f\"yolov4-tiny-logistics_size_416_{model_num}.cfg\")\n",
    "    )\n",
    "\n",
    "def get_outputs(model_num: int) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    net = cv2.dnn.readNet(*get_model_paths(model_num))\n",
    "\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    outputs = {}\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(logistics_path, filename)))\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image,\n",
    "                                     scalefactor = 1 / 255.,\n",
    "                                     size=(416, 416),\n",
    "                                     mean=(0, 0, 0),\n",
    "                                     swapRB=True,\n",
    "                                     crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outputs[filename[:-4]] = net.forward(output_layers)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def save_outputs(model_num: int, outputs: Dict[str, Tuple[np.ndarray, ...]]) -> None:\n",
    "    \"\"\"Save a dict of tuples of arrays to an HDF5 file.\"\"\"\n",
    "    path = get_path_in_storage(f\"outputs_{model_num}.h5\")\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        for key, tup in outputs.items():\n",
    "            grp = f.create_group(str(key))\n",
    "            for i, arr in enumerate(tup):\n",
    "                grp.create_dataset(\n",
    "                    f\"array_{i}\", data=arr, compression=\"gzip\", compression_opts=1\n",
    "                )\n",
    "\n",
    "def load_outputs(model_num: int) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    \"\"\"Load a dict of tuples of arrays from an HDF5 file.\"\"\"\n",
    "    path = get_path_in_storage(f\"outputs_{model_num}.h5\")\n",
    "    outputs_loaded = {}\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            grp = f[key]\n",
    "            arrays = tuple(np.array(grp[subkey]) for subkey in sorted(grp.keys()))\n",
    "            outputs_loaded[key] = arrays\n",
    "    return outputs_loaded\n",
    "\n",
    "def apply_nms(outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "              conf_threshold: float = 0.5,\n",
    "              nms_threshold: float = 0.4\n",
    "             ) -> Dict[str, Tuple[np.ndarray, ...]]:\n",
    "    \"\"\"\n",
    "    Apply Non-Max Suppression (NMS) to YOLO-style outputs.\n",
    "\n",
    "    Args:\n",
    "        outputs (dict): filename -> raw outputs from get_outputs()\n",
    "        conf_threshold (float): confidence threshold\n",
    "        nms_threshold (float): IoU threshold for NMS\n",
    "\n",
    "    Returns:\n",
    "        dict: filename -> tuple of np.ndarrays, same format as net.forward\n",
    "    \"\"\"\n",
    "    filtered_outputs = {}\n",
    "\n",
    "    for fname, layer_outputs in outputs.items():\n",
    "        detections = []\n",
    "\n",
    "        for out in layer_outputs:  # out shape: (N, 85)\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = detection[4] * scores[class_id]\n",
    "\n",
    "                if confidence > conf_threshold:\n",
    "                    cx, cy, w, h = detection[0:4]\n",
    "                    x = cx - w / 2\n",
    "                    y = cy - h / 2\n",
    "\n",
    "                    # build YOLO-style detection row\n",
    "                    det_row = np.zeros_like(detection)\n",
    "                    det_row[0:4] = [x, y, w, h]\n",
    "                    det_row[4] = detection[4]          # objectness\n",
    "                    det_row[5:] = 0.0\n",
    "                    det_row[5 + class_id] = scores[class_id]  # keep only top class\n",
    "\n",
    "                    detections.append((det_row, confidence))\n",
    "\n",
    "        if not detections:\n",
    "            filtered_outputs[fname] = (np.zeros((0, 85), dtype=np.float32),)\n",
    "            continue\n",
    "\n",
    "        # unpack for NMS\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        det_rows = []\n",
    "        for det_row, conf in detections:\n",
    "            x, y, w, h = det_row[0:4]\n",
    "            boxes.append([int(x), int(y), int(w), int(h)])\n",
    "            confidences.append(float(conf))\n",
    "            det_rows.append(det_row)\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            final = np.array([det_rows[i] for i in indices.flatten()], dtype=np.float32)\n",
    "        else:\n",
    "            final = np.zeros((0, 85), dtype=np.float32)\n",
    "\n",
    "        # wrap in tuple (to mimic net.forward output structure)\n",
    "        filtered_outputs[fname] = (final,)\n",
    "\n",
    "    return filtered_outputs"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First time running model",
   "id": "8e54855bb6c05eff"
  },
  {
   "cell_type": "code",
   "id": "91bfaa836499a083",
   "metadata": {},
   "source": "outputs_1 = get_outputs(1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:13:34.337335Z",
     "start_time": "2025-09-18T03:13:23.848159Z"
    }
   },
   "cell_type": "code",
   "source": "save_outputs(1, outputs_1)",
   "id": "2536310679ddc363",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T03:15:43.827397Z",
     "start_time": "2025-09-18T03:13:34.340057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs_2 = get_outputs(2)\n",
    "save_outputs(2, outputs_2)"
   ],
   "id": "5a2e16de9562d875",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# After first time",
   "id": "8051748b089f85b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:16:06.031556Z",
     "start_time": "2025-09-21T21:15:58.430258Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_1 = load_outputs(1)",
   "id": "83cfa9e015e96754",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:16:13.455137Z",
     "start_time": "2025-09-21T21:16:06.171733Z"
    }
   },
   "cell_type": "code",
   "source": "outputs_2 = load_outputs(2)",
   "id": "e06eaabec90b2acd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "outputs_1_nms = apply_nms(outputs_1)",
   "id": "a784e5b7f24e499e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "outputs_2_nms = apply_nms(outputs_2)",
   "id": "4c218a8b5f1f4944"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate Metrics",
   "id": "739e9c44b9fc1cc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Before NMS",
   "id": "d3b25956a328c161"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:21.914598Z",
     "start_time": "2025-09-21T21:22:21.911354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_ground_truths() -> Dict[str, np.ndarray]:\n",
    "    logistics_path = get_path_in_storage(\"logistics\")\n",
    "    res = {}\n",
    "\n",
    "    for filename in os.listdir(logistics_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(logistics_path, filename)\n",
    "\n",
    "            with open(filepath, \"r\") as f:\n",
    "                lines = []\n",
    "\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) == 5:  # expecting 5 values\n",
    "                        t = (\n",
    "                            int(parts[0]),\n",
    "                            float(parts[1]),\n",
    "                            float(parts[2]),\n",
    "                            float(parts[3]),\n",
    "                            float(parts[4]),\n",
    "                        )\n",
    "                        lines.append(t)\n",
    "\n",
    "                res[filename[:-4]] = np.array(lines)\n",
    "\n",
    "    return res"
   ],
   "id": "162773c6fde36e0a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:34.675662Z",
     "start_time": "2025-09-21T21:22:24.227377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.ops import box_iou\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "def cxcywh_to_xyxy(boxes: Tensor) -> Tensor:\n",
    "    # boxes: (N, 4) in [cx, cy, w, h]\n",
    "    xyxy = torch.zeros_like(boxes)\n",
    "    xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1\n",
    "    xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1\n",
    "    xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2\n",
    "    xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2\n",
    "    return xyxy\n",
    "\n",
    "def get_precision_and_recall(outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "                             ground_truths: Dict[str, np.ndarray],\n",
    "                             confidence_threshold: float,\n",
    "                             iou_threshold: float) -> Tuple[float, float]:\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    total_ground_truths = sum(len(gt) for _, gt in ground_truths.items())\n",
    "\n",
    "    for key in outputs:\n",
    "        output = outputs[key]\n",
    "        gt = ground_truths[key]\n",
    "\n",
    "        for feature_maps in output:\n",
    "            for detection in feature_maps:\n",
    "                box = detection[:4]\n",
    "                score = detection[4]\n",
    "                class_scores = detection[5:]\n",
    "                class_id = np.argmax(class_scores)\n",
    "\n",
    "                confidence = score * class_scores[class_id]\n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                total_predictions += 1\n",
    "\n",
    "                # Extract IDs (shape: N,)\n",
    "                gt_ids = gt[:, 0]\n",
    "\n",
    "                # Extract boxes (shape: N, 4)\n",
    "                gt_boxes = gt[:, 1:5]\n",
    "\n",
    "                boxes_xyxy = cxcywh_to_xyxy(torch.from_numpy(box).unsqueeze(0))\n",
    "                gts_xyxy = cxcywh_to_xyxy(torch.tensor(gt_boxes))\n",
    "\n",
    "                ious = box_iou(boxes_xyxy, gts_xyxy)[0]\n",
    "                for iou, gt_id in zip(ious, gt_ids):\n",
    "                    if iou >= iou_threshold and class_id == gt_id:\n",
    "                        # This is a correct prediction\n",
    "                        correct_predictions += 1\n",
    "                        continue\n",
    "\n",
    "    print(correct_predictions, total_predictions, total_ground_truths)\n",
    "    return correct_predictions / total_predictions, correct_predictions / total_ground_truths"
   ],
   "id": "67aa1d95546b0b9c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:22:42.394930Z",
     "start_time": "2025-09-21T21:22:34.680811Z"
    }
   },
   "cell_type": "code",
   "source": "gts: Dict[str, np.ndarray] = get_ground_truths()",
   "id": "c51a17840ec56840",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:23:05.345753Z",
     "start_time": "2025-09-21T21:22:42.402246Z"
    }
   },
   "cell_type": "code",
   "source": "get_precision_and_recall(outputs_1, gts, 0.5, 0.4)",
   "id": "bb7dd455a2112a67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/4sm5vl2d7_xdd0jwk0tgnhn00000gn/T/ipykernel_5596/790632341.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  boxes_xyxy = cxcywh_to_xyxy(torch.tensor([box]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11109 12059 36721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9212206650634381, 0.3025244410555268)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T21:23:27.322288Z",
     "start_time": "2025-09-21T21:23:05.357337Z"
    }
   },
   "cell_type": "code",
   "source": "get_precision_and_recall(outputs_2, gts, 0.5, 0.4)",
   "id": "56a30942b7e88bab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15183 16082 36721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9440989926626041, 0.4134691321042455)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-21T21:23:27.329307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sweep over confidence thresholds\n",
    "thresholds = np.linspace(0, 1, 50)\n",
    "iou_threshold = 0.4\n",
    "\n",
    "precisions_1, recalls_1 = [], []\n",
    "precisions_2, recalls_2 = [], []\n",
    "\n",
    "for t in thresholds:\n",
    "    p1, r1 = get_precision_and_recall(outputs_1, gts, t, iou_threshold)\n",
    "    p2, r2 = get_precision_and_recall(outputs_2, gts, t, iou_threshold)\n",
    "\n",
    "    precisions_1.append(p1)\n",
    "    recalls_1.append(r1)\n",
    "    precisions_2.append(p2)\n",
    "    recalls_2.append(r2)\n",
    "\n",
    "# Plot PR curves\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recalls_1, precisions_1, label=\"Model 1\", marker=\"o\", markersize=3, linestyle=\"-\")\n",
    "plt.plot(recalls_2, precisions_2, label=\"Model 2\", marker=\"s\", markersize=3, linestyle=\"-\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "c9d2dd0e70bbb242",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41536 24145875 36721\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## After NMS",
   "id": "74f1499d9964d27b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Manager\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def worker(model_name: str,\n",
    "           outputs: Dict[str, Tuple[np.ndarray, ...]],\n",
    "           gts: Dict[str, np.ndarray],\n",
    "           conf_threshold: float,\n",
    "           iou_threshold: float,\n",
    "           return_dict):\n",
    "    \"\"\"\n",
    "    Worker function to compute precision/recall for a given model.\n",
    "    \"\"\"\n",
    "    precision, recall = get_precision_and_recall(outputs, gts, conf_threshold, iou_threshold)\n",
    "    return_dict[model_name] = (precision, recall)\n",
    "\n",
    "\n",
    "def evaluate_models_with_mp(output_1_nms, output_2_nms, gts,\n",
    "                            conf_threshold: float = 0.5,\n",
    "                            iou_threshold: float = 0.4):\n",
    "    \"\"\"\n",
    "    Run per-class precision/recall evaluation in parallel\n",
    "    using multiprocessing with shared memory.\n",
    "    \"\"\"\n",
    "    with Manager() as manager:\n",
    "        # Shared dictionary for results\n",
    "        return_dict = manager.dict()\n",
    "\n",
    "        # Launch processes\n",
    "        p1 = mp.Process(target=worker,\n",
    "                        args=(\"model_1\", output_1_nms, gts, conf_threshold, iou_threshold, return_dict))\n",
    "        p2 = mp.Process(target=worker,\n",
    "                        args=(\"model_2\", output_2_nms, gts, conf_threshold, iou_threshold, return_dict))\n",
    "\n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p1.join()\n",
    "        p2.join()\n",
    "\n",
    "        results = dict(return_dict)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# gts = get_ground_truths()\n",
    "# results = evaluate_models_with_mp(output_1_nms, output_2_nms, gts, 0.5, 0.4)\n",
    "# print(results)  # {\"model_1\": (precision, recall), \"model_2\": (precision, recall)}"
   ],
   "id": "8fd1307cef811a4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import shared_memory\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "def dict_to_shm(dict_data: Dict[str, np.ndarray]):\n",
    "    \"\"\"\n",
    "    Store dict of numpy arrays in shared memory.\n",
    "    Returns (shm_dict, shapes, dtypes) for reconstruction.\n",
    "    \"\"\"\n",
    "    shm_dict = {}\n",
    "    shapes, dtypes = {}, {}\n",
    "    for k, arr in dict_data.items():\n",
    "        arr = np.asarray(arr)\n",
    "        shm = shared_memory.SharedMemory(create=True, size=arr.nbytes)\n",
    "        shm_arr = np.ndarray(arr.shape, dtype=arr.dtype, buffer=shm.buf)\n",
    "        shm_arr[:] = arr[:]  # copy data into shared block\n",
    "        shm_dict[k] = shm.name\n",
    "        shapes[k] = arr.shape\n",
    "        dtypes[k] = arr.dtype.str\n",
    "    return shm_dict, shapes, dtypes\n",
    "\n",
    "\n",
    "def shm_to_dict(shm_dict, shapes, dtypes):\n",
    "    \"\"\"\n",
    "    Reconstruct dict of numpy arrays from shared memory handles.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for k, name in shm_dict.items():\n",
    "        shm = shared_memory.SharedMemory(name=name)\n",
    "        arr = np.ndarray(shapes[k], dtype=np.dtype(dtypes[k]), buffer=shm.buf)\n",
    "        res[k] = arr\n",
    "    return res\n",
    "\n",
    "\n",
    "def worker(model_name: str,\n",
    "           shm_outputs, outputs_shapes, outputs_dtypes,\n",
    "           shm_gts, gts_shapes, gts_dtypes,\n",
    "           conf_threshold: float,\n",
    "           iou_threshold: float,\n",
    "           return_dict):\n",
    "    \"\"\"\n",
    "    Worker: compute per-class precision/recall.\n",
    "    \"\"\"\n",
    "    outputs = shm_to_dict(shm_outputs, outputs_shapes, outputs_dtypes)\n",
    "    gts = shm_to_dict(shm_gts, gts_shapes, gts_dtypes)\n",
    "\n",
    "    # ðŸ”‘ Call your existing function that computes *per-class* precision & recall\n",
    "    per_class_results = get_precision_and_recall(outputs, gts, conf_threshold, iou_threshold)\n",
    "\n",
    "    return_dict[model_name] = per_class_results\n",
    "\n",
    "\n",
    "def evaluate_models_with_mp(output_1_nms, output_2_nms, gts,\n",
    "                            conf_threshold: float = 0.5,\n",
    "                            iou_threshold: float = 0.4):\n",
    "    \"\"\"\n",
    "    Parallel per-class precision/recall evaluation with true shared memory.\n",
    "    \"\"\"\n",
    "    # Store in shared memory\n",
    "    shm_out1, out1_shapes, out1_dtypes = dict_to_shm(output_1_nms)\n",
    "    shm_out2, out2_shapes, out2_dtypes = dict_to_shm(output_2_nms)\n",
    "    shm_gts, gts_shapes, gts_dtypes = dict_to_shm(gts)\n",
    "\n",
    "    with mp.Manager() as manager:\n",
    "        return_dict = manager.dict()\n",
    "\n",
    "        p1 = mp.Process(target=worker,\n",
    "                        args=(\"model_1\", shm_out1, out1_shapes, out1_dtypes,\n",
    "                              shm_gts, gts_shapes, gts_dtypes,\n",
    "                              conf_threshold, iou_threshold, return_dict))\n",
    "        p2 = mp.Process(target=worker,\n",
    "                        args=(\"model_2\", shm_out2, out2_shapes, out2_dtypes,\n",
    "                              shm_gts, gts_shapes, gts_dtypes,\n",
    "                              conf_threshold, iou_threshold, return_dict))\n",
    "\n",
    "        p1.start()\n",
    "        p2.start()\n",
    "        p1.join()\n",
    "        p2.join()\n",
    "\n",
    "        results = dict(return_dict)\n",
    "\n",
    "    return results\n"
   ],
   "id": "8c98aef8abf479df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "techtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
